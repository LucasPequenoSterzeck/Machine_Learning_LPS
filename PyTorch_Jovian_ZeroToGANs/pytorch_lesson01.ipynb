{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasPequenoSterzeck/Machine_Learning_LPS/blob/main/PyTorch_Jovian_ZeroToGANs/pytorch_lesson01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKDkYeabFnSb"
      },
      "source": [
        "# pytorch-lesson01\n",
        "\n",
        "This notebook will be used foor practice in Lesson 1 PyTorch on Jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q96odn5cFnSd"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Brkd5Rf1FnSe",
        "outputId": "d87750ea-aab7-4f2e-d6e3-c7b2af0234be",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Aqui temos um tensor de 1 dimensão: tensor([4., 2., 1.]) |\n",
            "Dimensões: torch.Size([3])\n",
            "\n",
            "--> Aqui temos um tensor de 3 dimensão: tensor([[4., 2., 1.],\n",
            "        [4., 2., 1.]]) |\n",
            "Dimensões: torch.Size([2, 3])\n",
            "\n",
            "--> Aqui temos um tensor de 4 dimensão: tensor([[[4., 2., 1.],\n",
            "         [4., 2., 1.]],\n",
            "\n",
            "        [[4., 2., 1.],\n",
            "         [4., 2., 1.]]]) |\n",
            "Dimensões: torch.Size([2, 2, 3])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tensores são matrizes! podemos ter diversas dimensões, as mais comuns são:\n",
        "\n",
        "# 1 Dimensão\n",
        "t1 = torch.tensor([4.,2,1])\n",
        "print(f'--> Aqui temos um tensor de 1 dimensão: {t1} |\\nDimensões: {t1.shape}\\n')\n",
        "\n",
        "# 3 Dimensão\n",
        "t2 = torch.tensor([[4.,2,1],[4.,2,1]])\n",
        "print(f'--> Aqui temos um tensor de 3 dimensão: {t2} |\\nDimensões: {t2.shape}\\n')\n",
        "\n",
        "# 3 Dimensão\n",
        "t3 = torch.tensor([[[4.,2,1],[4.,2,1]],[[4.,2,1],[4.,2,1]]])\n",
        "print(f'--> Aqui temos um tensor de 4 dimensão: {t3} |\\nDimensões: {t3.shape}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnfxgRXUFnSf"
      },
      "source": [
        "Na criação de tensores temos opção de habilitar \"requires_grad\", essa função irá possibilitar o retrocesso dos valores via \".backward()\" conforme demonstrado abaixo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz6rBEobFnSf",
        "outputId": "980afe55-22b0-4a12-b80d-63d39fc2947e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = 3.0\n",
            "w = 4.0\n",
            "b = 5.0\n",
            "\n",
            "y = 17.0\n",
            "x = 3.0\n",
            "w = 4.0\n",
            "b = 5.0\n",
            "\n",
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Criando tensores com opção \"requires_grad\"\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "print(f'x = {x}\\nw = {w}\\nb = {b}\\n')\n",
        "\n",
        "# operação aritmética:\n",
        "y = w * x + b\n",
        "print(f'y = {y}')\n",
        "print(f'x = {x}\\nw = {w}\\nb = {b}\\n')\n",
        "\n",
        "# Ao chamar y.backward(), o PyTorch calcula automaticamente os gradientes de y em relação aos tensores...\n",
        "# com requires_grad=True, ou seja, w e b. Os gradientes são então armazenados nos atributos grad dos respectivos tensores.\n",
        "y.backward()\n",
        "\n",
        "# Verificando gradientes\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du0iG_vWFnSg",
        "outputId": "ad890b82-3155-491f-fc6b-9d0d5b3aba40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2.],\n",
              "         [3., 4.]],\n",
              "\n",
              "        [[1., 2.],\n",
              "         [3., 4.]],\n",
              "\n",
              "        [[1., 2.],\n",
              "         [3., 4.]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Integração com Numpy:\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([[[1, 2], [3, 4.]],[[1, 2], [3, 4.]],[[1, 2], [3, 4.]]])\n",
        "\n",
        "# Convertendo de Numpy para Tensor Torch\n",
        "y = torch.from_numpy(x)\n",
        "y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NH3pUOiFnSg"
      },
      "source": [
        "Banco de dados que usaremos para criar lógicas:\n",
        "\n",
        "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n",
        "\n",
        "Iremos prever a produção de Maçãs(Apples) e Laranjas(Oranges) in toneladas (ton), considerando que cada fruta será uma regressão a parte (Já que não estamos trabalhando com regressão multinível), teremos:\n",
        "\n",
        "> **yield_apple**  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "\n",
        "> **yield_orange** = w21 * temp + w22 * rainfall + w23 * humidity + b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HOcSNhyFnSg",
        "outputId": "e113e6f4-abaf-455b-ee63-527e86d5e0bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Criando banco de dados:\n",
        "\n",
        "# Input (temp, rainfall, humidity) <- Valores presentes nas colunas 1 a 3\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "# Targets (apples, oranges) <- Valores alvo que queremos prever\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')\n",
        "# Convertendo tudo para Torch\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXag111zFnSh"
      },
      "outputs": [],
      "source": [
        "# Agora que temos os dados, vamos configurar como o modelo irá mensurar o erro\n",
        "# utilizaremos o Minimo Erro Quadrático ou MSE\n",
        "\n",
        "def mse(t1, t2):\n",
        "    # t1 são valores target/reais;\n",
        "    # t2 são valores que o modelo encontrou como target/previsões\n",
        "    # diff é a diferença de um para outro\n",
        "    diff = t1 - t2\n",
        "    # realizados diff * diff para elevar a diferença eliminando assim números negativos\n",
        "    # o resultado será dívidido pela quantidade de termos presentes (diff.numel())\n",
        "    return torch.sum(diff * diff) / diff.numel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eCaqaFnFnSh"
      },
      "source": [
        "O calculo do gradiante será realizado e ajustado de acordo com o erro que encontrarmos, por isso que a etapa acima é tão importante para o modelo.\n",
        "\n",
        "Abaixo exemplo gráfico, nosso objetivo com essa imagem é sempre chegar o ponto mais \"baixo\" possível do gradiante, pois é lá onde o erro é o menor possível.\n",
        "\n",
        "![postive-gradient](https://i.imgur.com/WLzJ4xP.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jtq0A2dF-dQ"
      },
      "source": [
        "# Linear regression model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_mHrDaAGAkQ",
        "outputId": "ed2ca02f-c2cd-4e35-d161-233ee14a364d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2310, -0.0236, -0.3587],\n",
            "        [-0.3754, -0.8476,  0.3598]], requires_grad=True)\n",
            "tensor([-0.9626,  2.1724], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# W simbolizará relações que serão multiplicadas pelas colunas pra que encontremos os valores procurados;\n",
        "# B são a influência aplicada que irá nos gerar os valores de predição\n",
        "\n",
        "# Weights and biases\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "# torch.randn creates a tensor with the given shape, with elements picked randomly from a normal distribution with mean 0 and standard deviation 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFIh6twmGeJf"
      },
      "outputs": [],
      "source": [
        "# Nosso modelo será elaborado da seguinte forma:\n",
        "def model(x):\n",
        "    return x @ w.t() + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyh8mEmpGhkP"
      },
      "source": [
        "O que o modelo irá realizar:\n",
        "\n",
        "![matrix-mult](https://i.imgur.com/WGXLFvA.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThIP9lYzGr7v"
      },
      "source": [
        "Na primeira Linha de X, modelo irá fazer 73 x w11, 67 x W12 e 43 x w13 + b1.\n",
        "\n",
        "Da mesma forma será feito com a segunda coluna de W:\n",
        "  73 x w21\n",
        "  67 x w22\n",
        "  43 x w23\n",
        "  '+ b2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GINbXqSGqZX",
        "outputId": "98534bac-fbef-4d0d-ec15-50e7b0194d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores que nosso modelo preveu para cada caso:\n",
            "tensor([[  14.2309,  -63.7383],\n",
            "        [  25.2311,  -74.7806],\n",
            "        [  25.3634,  -57.5764],\n",
            "        [  -0.5075, -110.1792],\n",
            "        [  36.7349,  -42.1841]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Valores que precisamos chegar, para cada casoi:\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ],
      "source": [
        "# Valores que nosso modelo chegou atualmente\n",
        "print('Valores que nosso modelo preveu para cada caso:')\n",
        "preds = model(inputs)\n",
        "print(preds)\n",
        "\n",
        "# Alvo que é o valor referência\n",
        "print('\\nValores que precisamos chegar, para cada casoi:')\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGy2dYBlItIo"
      },
      "source": [
        "Perceba que em alguns casos nosso modelo preveu valores negativos, o que não é um bom indício, mas tudo bem, estamos falando da primeira versão dele, e consideremos que ele foi inicializado com pesos aleatórios, o que precisamos agora é **computar o erro** e conseguir evoluir apartir desse ponto, para isso precisamos aplicar uma metrica aos erros, que será **mse** já apresentado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J20KhknxJFKa"
      },
      "outputs": [],
      "source": [
        "# MSE loss\n",
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc_RtUJxJG-n",
        "outputId": "7b590732-39c9-4fd3-c1d0-c863e0d2f539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(15126.6465, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlyOQGaCJMO3",
        "outputId": "63633a2e-bcb2-47d3-c19c-f21ed0b680f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores W antes de realizar backward:\n",
            "tensor([[-0.3029,  0.0696,  0.7138],\n",
            "        [-1.2952,  0.2986,  0.2857]], requires_grad=True)\n",
            "None\n",
            "\n",
            "Valores W após backward:\n",
            "tensor([[-0.3029,  0.0696,  0.7138],\n",
            "        [-1.2952,  0.2986,  0.2857]], requires_grad=True)\n",
            "tensor([[ -4627.7129,  -5516.5557,  -3253.5088],\n",
            "        [-13694.6133, -14353.7559,  -8956.5312]])\n"
          ]
        }
      ],
      "source": [
        "print('Valores W antes de realizar backward:')\n",
        "print(w)\n",
        "print(w.grad)\n",
        "\n",
        "print('\\nValores W após backward:')\n",
        "loss.backward()\n",
        "print(w)\n",
        "print(w.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-msl3OJJl8P"
      },
      "source": [
        "## Ajustando os pesos para buscar reduzir o erro\n",
        "\n",
        "A perca/erro é uma função quadrática dos pesos, então nosso objetivo é encontrar o conjunto de pesos onde o erro é menor.\n",
        "\n",
        "**Se o elemento que encontrarmos for POSITIVO, então:**\n",
        "<br>\n",
        "> + AUMENTAR os pesos do elemento farão que o erro aumente;\n",
        "> + DIMINUIR os pesos do elemento farão que o erro diminua;\n",
        "\n",
        "![postive-gradient](https://i.imgur.com/WLzJ4xP.png)\n",
        "------------------------\n",
        "\n",
        "**Se o elemento que encontrarmos for NEGATIVO, então:**\n",
        "<br>\n",
        "> + AUMENTAR os pesos do elemento farão que o erro diminua;\n",
        "> + DIMINUIR os pesos do elemento farão que o erro aumente;\n",
        "\n",
        "![negative=gradient](https://i.imgur.com/dvG2fxU.png)\n",
        "------------------------\n",
        "\n",
        "Agora o único ponto que devemos tomar cuidado é o quanto (Qual a intensidade) que iremos acatar essa direção, se dermos passos muito distantes podemos jogar o modelo \"para longe\", por conta disso sempre iniciamos a adotar pequenas alterações sempre na direção que diminua nosso erro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrNWY8MaLM6Y"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dSX-XNUL--4",
        "outputId": "0f71f01c-bc06-417c-8122-3c0261842c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(15126.6465, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Agora vamos verificar para ver se o erro está menor:\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGQ9hxWWMEDY",
        "outputId": "6d153dc9-34e4-4b4b-aa37-d914dc3a9ebd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ],
      "source": [
        "# Agora vamos refazer o processo\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEbhydotMIzR",
        "outputId": "e97a166a-be68-4483-f626-4a0f964a367d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 22.7048, -40.2713],\n",
            "        [ 36.3797, -43.9534],\n",
            "        [ 38.6693, -21.2317],\n",
            "        [  7.7892, -86.7231],\n",
            "        [ 47.5020, -12.6840]], grad_fn=<AddBackward0>)\n",
            "tensor(10244.1299, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)\n",
        "# Calculate the loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB6x90q7MMgg",
        "outputId": "52efa04d-e11a-4430-cb36-4e1cb782f8c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ -3751.7290,  -4572.1133,  -2671.4485],\n",
            "        [-11272.9346, -11754.5742,  -7351.9507]])\n",
            "tensor([ -45.5910, -132.9727])\n"
          ]
        }
      ],
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SQvPis-MPRX",
        "outputId": "50eb2322-6ee8-4763-c337-490655a1f361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2191,  0.1705,  0.7731],\n",
            "        [-1.0455,  0.5597,  0.4488]], requires_grad=True)\n",
            "tensor([ 0.9839, -1.4819], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Adjust weights & reset gradients\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FydFy4gAMPWY",
        "outputId": "b3f2e04f-e32d-4a32-eb90-4067653e4af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6953.2549, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Calculate loss\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJB2ToCMMWqQ"
      },
      "source": [
        "Para agilizar vamos criar um loop e repetir o processo 1000 vezes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nivd4u5JMWPJ"
      },
      "outputs": [],
      "source": [
        "# Train for 1000 epochs\n",
        "for i in range(1000):\n",
        "    preds = model(inputs)\n",
        "    loss = mse(preds, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk4c8LIKMd8u",
        "outputId": "b4286461-e3e6-4b95-9f73-02068e17ba81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5134, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Verificando modelo após 1000 epochs\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFfzHZB9Mr8P"
      },
      "source": [
        "# Linear regression using PyTorch built-ins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5X3sPL12Mrap"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [74, 66, 43],\n",
        "                   [91, 87, 65],\n",
        "                   [88, 134, 59],\n",
        "                   [101, 44, 37],\n",
        "                   [68, 96, 71],\n",
        "                   [73, 66, 44],\n",
        "                   [92, 87, 64],\n",
        "                   [87, 135, 57],\n",
        "                   [103, 43, 36],\n",
        "                   [68, 97, 70]],\n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119],\n",
        "                    [57, 69],\n",
        "                    [80, 102],\n",
        "                    [118, 132],\n",
        "                    [21, 38],\n",
        "                    [104, 118],\n",
        "                    [57, 69],\n",
        "                    [82, 100],\n",
        "                    [118, 134],\n",
        "                    [20, 38],\n",
        "                    [102, 120]],\n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora para a parte de separar Treino e Teste, iremos utilizar:\n",
        "\n",
        "## Primeiro: TensorDataset do Torch para juntar os inputs e targets em uma variavel só\n",
        "from torch.utils.data import TensorDataset\n",
        "# Define dataset\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "print('Aqui está somente três linhas de input e target: \\n',train_ds[0:3],'\\n') # Isso irá permitirmos manipular todo o dataset como particionamento de listas\n",
        "\n",
        "## Segundo: Agora definimos o tamanho do batch_size que iremos utilizar\n",
        "from torch.utils.data import DataLoader\n",
        "# Define data loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "\n",
        "# Exemplo de utilização dos dados:\n",
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUJByvrkbXxY",
        "outputId": "639e4953-b5a5-4a38-e7a0-e8a0ea8c1052"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aqui está somente três linhas de input e target: \n",
            " (tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.]])) \n",
            "\n",
            "tensor([[69., 96., 70.],\n",
            "        [91., 88., 64.],\n",
            "        [92., 87., 64.],\n",
            "        [68., 97., 70.],\n",
            "        [73., 67., 43.]])\n",
            "tensor([[103., 119.],\n",
            "        [ 81., 101.],\n",
            "        [ 82., 100.],\n",
            "        [102., 120.],\n",
            "        [ 56.,  70.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Da forma que definimos acima cada interação que realizarmos irá tratar 5 linhas, já que definimos o batch_size para 5.\n",
        "# Além disso habilitamos aleatóriedade, o que irá trazer robustes ao nosso treinamento.\n",
        "\n",
        "# Definindo o modelo:\n",
        "model = nn.Linear(3, 2) # Nosso modelo receberá 3 input's para prever 2 target's. (3,2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0TTKsMccQZD",
        "outputId": "8769952e-6712-40f8-eda7-7c32c48ab0ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3297,  0.0941, -0.1895],\n",
            "        [-0.3661, -0.0613, -0.4158]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.2956, 0.4969], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters (Acessamos os valores valores acima quando solicitamos parametes())\n",
        "list(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blE9HDlacpPL",
        "outputId": "de5c5892-fad0-4d0d-a9e8-4e9d51c41ee0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.3297,  0.0941, -0.1895],\n",
              "         [-0.3661, -0.0613, -0.4158]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2956, 0.4969], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando previsões com o modelo (Para isso iremos inserir os input's ao modelo)\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvzgog_1cwoq",
        "outputId": "78cf69ac-00dc-40a7-fd1b-ccd6d76db357"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-25.6137, -48.2178],\n",
              "        [-33.5507, -64.8277],\n",
              "        [-26.7670, -63.6878],\n",
              "        [-36.2957, -54.8693],\n",
              "        [-26.6819, -59.7584],\n",
              "        [-26.0374, -48.5226],\n",
              "        [-33.8342, -65.1823],\n",
              "        [-27.2861, -64.4697],\n",
              "        [-35.8719, -54.5645],\n",
              "        [-26.5417, -59.8081],\n",
              "        [-25.8972, -48.5723],\n",
              "        [-33.9744, -65.1326],\n",
              "        [-26.4834, -63.3332],\n",
              "        [-36.4359, -54.8196],\n",
              "        [-26.2581, -59.4535]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora ao invez de definirmos manualmente a função de perca, podemos utilizar uma das funções já existentes de perca/erro do Torch:\n",
        "\n",
        "import torch.nn.functional as F\n",
        "loss_fn = F.mse_loss\n",
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp7ngXpoc4ob",
        "outputId": "be86c8d6-8bd9-42fb-fc24-199e9985b4a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18175.6074, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceba que tivemos um erro de 18175.60, será que conseguimos reduzi-lo? Vamos ver abaixo!\n",
        "\n",
        "# Para conseguimos alterar o modelo agora que temos uma função de erro, iremos precisar de um otimizador**\n",
        "# ** Otimizador fará o gradiente caminhar para o caminho do menor erro\n",
        "\n",
        "# Vamos aprevitar um optimizador presente na biblioteca do torch, e vamos definir uma taxa de aprendizado'lr' baixa:\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "CExbRU8rdGr7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinano o modelo!\n",
        "\n",
        "Agora vamos começar a literalmente treinar o modelo, vamos seguir os seguintes passos para aprimorar o gradiente descendent:\n",
        "\n",
        "> **1º Passo:** Gerar as previsões;<br>\n",
        "> **2º Passo:** Calcular o erro;<br>\n",
        "> **3º Passo:** Computar os gradientes de w,r e t de pesos e biases;<br>\n",
        "> **4º Passo:** Ajustar os pesos por subtração pequena quantia;<br>\n",
        "> **5º Passo:** Resetar os gradientes atuais para zero;<br>\n",
        "> E então voltar ao 1º Passo.<br>\n",
        "\n",
        "E um ponto importante é que, ao invez de cada loop citado acima (passo 1 ao 5) utilizarmos todo o dataset, nós iremos correr somente um dos batch's por vez até finalizar todo o dataset, que conforme definimos terão somente 5 'linhas' de dados em cada interação. Cada vez que modelo realizar esse loop completo chamaremos de uma epoch."
      ],
      "metadata": {
        "id": "IVMdJpTld3g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Deixando todos os passos em uma função que chamaremos de fit:\n",
        "def fit(num_epochs, model, loss_fn, opt, traiin_dl):\n",
        "  # Criando o loop para cada epoch:\n",
        "  for epoch in range(num_epochs):\n",
        "    # Treinar com os batchs:\n",
        "    for xb, yb in train_dl:\n",
        "      # 1 passo: Previsões\n",
        "      pred = model(xb)\n",
        "      # 2 passo: erro\n",
        "      loss = loss_fn(pred, yb)\n",
        "      # 3 passo: Computar o grandiente\n",
        "      loss.backward()\n",
        "      # 4 passo: Optmizar parâmetros\n",
        "      opt.step()\n",
        "      # 5 passo: resetando gradientes\n",
        "      opt.zero_grad()\n",
        "    # Imprimindo o processo a cada 10 epoch:\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {round(loss.item(),4)}')\n",
        "\n",
        "fit(100, model, loss_fn, opt, train_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iGWMewue-aH",
        "outputId": "32e5361a-c20c-4829-b173-73b19b73b6eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 51.4335\n",
            "Epoch [20/100], Loss: 21.3999\n",
            "Epoch [30/100], Loss: 26.4932\n",
            "Epoch [40/100], Loss: 31.5152\n",
            "Epoch [50/100], Loss: 7.0611\n",
            "Epoch [60/100], Loss: 31.6652\n",
            "Epoch [70/100], Loss: 27.6101\n",
            "Epoch [80/100], Loss: 26.5498\n",
            "Epoch [90/100], Loss: 21.7098\n",
            "Epoch [100/100], Loss: 4.3935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos agora comparar valores previstos com os valore reais:\n",
        "\n",
        "pred = model(inputs)\n",
        "print(f'Aqui estão valores que foram previstos pelo modelo:\\n{pred}\\n')\n",
        "print(f'Aqui estão valores REAIS:\\n{targets}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WTgBu5Kgb8R",
        "outputId": "da23820b-82a6-4756-8f18-58ac863fe693"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aqui estão valores que foram previstos pelo modelo:\n",
            "tensor([[ 57.4404,  71.0151],\n",
            "        [ 80.1549,  97.4492],\n",
            "        [122.3411, 139.3025],\n",
            "        [ 22.6236,  40.1365],\n",
            "        [ 97.5514, 111.8012],\n",
            "        [ 56.1647,  69.8809],\n",
            "        [ 79.6346,  96.9543],\n",
            "        [122.4319, 139.5814],\n",
            "        [ 23.8993,  41.2708],\n",
            "        [ 98.3068, 112.4405],\n",
            "        [ 56.9201,  70.5202],\n",
            "        [ 78.8792,  96.3149],\n",
            "        [122.8614, 139.7974],\n",
            "        [ 21.8682,  39.4972],\n",
            "        [ 98.8271, 112.9355]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Aqui estão valores REAIS:\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]])\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}