{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch-lesson01\n",
    "\n",
    "This notebook will be used foor practice in Lesson 1 PyTorch on Jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Aqui temos um tensor de 1 dimensão: tensor([4., 2., 1.]) |\n",
      "Dimensões: torch.Size([3])\n",
      "\n",
      "--> Aqui temos um tensor de 3 dimensão: tensor([[4., 2., 1.],\n",
      "        [4., 2., 1.]]) |\n",
      "Dimensões: torch.Size([2, 3])\n",
      "\n",
      "--> Aqui temos um tensor de 4 dimensão: tensor([[[4., 2., 1.],\n",
      "         [4., 2., 1.]],\n",
      "\n",
      "        [[4., 2., 1.],\n",
      "         [4., 2., 1.]]]) |\n",
      "Dimensões: torch.Size([2, 2, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tensores são matrizes! podemos ter diversas dimensões, as mais comuns são:\n",
    "\n",
    "# 1 Dimensão\n",
    "t1 = torch.tensor([4.,2,1])\n",
    "print(f'--> Aqui temos um tensor de 1 dimensão: {t1} |\\nDimensões: {t1.shape}\\n')\n",
    "\n",
    "# 3 Dimensão\n",
    "t2 = torch.tensor([[4.,2,1],[4.,2,1]])\n",
    "print(f'--> Aqui temos um tensor de 3 dimensão: {t2} |\\nDimensões: {t2.shape}\\n')\n",
    "\n",
    "# 3 Dimensão\n",
    "t3 = torch.tensor([[[4.,2,1],[4.,2,1]],[[4.,2,1],[4.,2,1]]])\n",
    "print(f'--> Aqui temos um tensor de 4 dimensão: {t3} |\\nDimensões: {t3.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na criação de tensores temos opção de habilitar \"requires_grad\", essa função irá possibilitar o retrocesso dos valores via \".backward()\" conforme demonstrado abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 3.0\n",
      "w = 4.0\n",
      "b = 5.0\n",
      "\n",
      "y = 17.0\n",
      "x = 3.0\n",
      "w = 4.0\n",
      "b = 5.0\n",
      "\n",
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Criando tensores com opção \"requires_grad\"\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "print(f'x = {x}\\nw = {w}\\nb = {b}\\n')\n",
    "\n",
    "# operação aritmética:\n",
    "y = w * x + b\n",
    "print(f'y = {y}')\n",
    "print(f'x = {x}\\nw = {w}\\nb = {b}\\n')\n",
    "\n",
    "# Ao chamar y.backward(), o PyTorch calcula automaticamente os gradientes de y em relação aos tensores...\n",
    "# com requires_grad=True, ou seja, w e b. Os gradientes são então armazenados nos atributos grad dos respectivos tensores.\n",
    "y.backward()\n",
    "\n",
    "# Verificando gradientes\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [3., 4.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integração com Numpy:\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[[1, 2], [3, 4.]],[[1, 2], [3, 4.]],[[1, 2], [3, 4.]]])\n",
    "\n",
    "# Convertendo de Numpy para Tensor Torch\n",
    "y = torch.from_numpy(x)\n",
    "y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Banco de dados que usaremos para criar lógicas:\n",
    "\n",
    "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n",
    "\n",
    "Iremos prever a produção de Maçãs(Apples) e Laranjas(Oranges) in toneladas (ton), considerando que cada fruta será uma regressão a parte (Já que não estamos trabalhando com regressão multinível), teremos:\n",
    "\n",
    "> **yield_apple**  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "\n",
    "> **yield_orange** = w21 * temp + w22 * rainfall + w23 * humidity + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando banco de dados:\n",
    "\n",
    "# Input (temp, rainfall, humidity) <- Valores presentes nas colunas 1 a 3\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "# Targets (apples, oranges) <- Valores alvo que queremos prever\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')\n",
    "# Convertendo tudo para Torch\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46/99414273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "# Agora que temos os dados, vamos configurar como o modelo irá mensurar o erro\n",
    "# utilizaremos o Minimo Erro Quadrático ou MSE\n",
    "\n",
    "def mse(t1, t2):\n",
    "    # t1 são valores target/reais;\n",
    "    # t2 são valores que o modelo encontrou como target/previsões\n",
    "    # diff é a diferença de um para outro\n",
    "    diff = t1 - t2\n",
    "    # realizados diff * diff para elevar a diferença eliminando assim números negativos\n",
    "    # o resultado será dívidido pela quantidade de termos presentes (diff.numel())\n",
    "    return torch.sum(diff * diff) / diff.numel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O calculo do gradiante será realizado e ajustado de acordo com o erro que encontrarmos, por isso que a etapa acima é tão importante para o modelo.\n",
    "\n",
    "Abaixo exemplo gráfico, nosso objetivo com essa imagem é sempre chegar o ponto mais \"baixo\" possível do gradiante, pois é lá onde o erro é o menor possível.\n",
    "\n",
    "![postive-gradient](https://i.imgur.com/WLzJ4xP.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}